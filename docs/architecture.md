<p align="center">
  <strong style="font-size: 2em; letter-spacing: 0.1em;">â€¢UNIâ€¢</strong><br>
  <em>The Worldâ€™s First Conversational Generative Emotion Interface (CGEI)</em>
</p>

---

Welcome to <strong>â€¢UNIâ€¢</strong> (pronounced â€œyou-n-eyeâ€) â€” a messaging experience that turns every conversation into living art, powered by emotion, AI, and human connection.

> <strong>â€¢UNIâ€¢</strong> is not just a chat app.
> Itâ€™s a new interface for feeling, remembering, and sharing â€” where the canvas of every message is finally alive.

---

This document outlines the technical architecture for â€¢UNIâ€¢ â€” the first Conversational Generative Emotion Interface (CGEI). The goal is to define how text, emotion, AI, and generative art work together in real-time to power the â€¢UNIâ€¢ experience.

---

## ğŸ§­ Core Flow: Message â†’ Emotion â†’ Output


---

## âš™ï¸ Stack Overview

| Layer | Tool / API | Purpose |
|-------|------------|---------|
| Frontend | Flutter OR React Native | Cross-platform mobile UI (iOS + Android) |
| Realtime DB | Firebase / Supabase | Messaging, auth, presence |
| Emotion Analysis | Google Cloud Natural Language | Detects sentiment & emotion |
| LLM Response | OpenAI GPT-4 | Drives â€¢UNIâ€¢ personaâ€™s voice |
| Visual Generation | DALLÂ·E OR Stable Diffusion | Generates full-screen scenes, memory visuals |
| Audio Generation | Google Cloud TTS (optional) | Spoken â€¢UNIâ€¢ responses |
| Canvas Animation | WebGL, â€¢UNIâ€¢ty, or p5.js | Bubble morphing, ambient animation |

---

## ğŸ’¬ 1. Realtime Messaging Core

- Built on Firebase or Supabase  
- Stores messages with timestamps, user ID, and emotion metadata
- Listens to incoming message events to trigger downstream reactions

---

## ğŸ§  2. Emotion Detection Pipeline

- Incoming messages sent to Google NLP API
- Returns:
  - Sentiment Score (â€“1.0 to +1.0)
  - Emotion Labels (joy, anger, sadness, etc.)
  - Key Phrases / Entities
- Triggers:
  - Visual scene generation
  - Bubble animation effects
  - â€¢UNIâ€¢ tone modulation

---

## ğŸ­ 3. â€¢UNIâ€¢ Persona (LLM Response)

- GPT-4 generates brief, in-character responses after each message
- Prompt includes:
  - Recent messages (limited history)
  - Sentiment metadata
  - Personality description (cheerful, supportive, witty)
- Configurable temperature for tone

---

## ğŸ–¼ 4. Generative Art Engine

**For backgrounds:**
- Text-to-image model (DALLÂ·E or SDXL) generates ambient scene
- Input prompt blends:
  - Detected emotion
  - Contextual keywords
  - Conversation theme

**For story cards:**
- Chat + photo â†’ narrative caption + visual scene
- Outputs are stored in Memory Deck

---

## ğŸ’¬ 5. Morphing Chat Bubbles

- Built using:
  - WebGL custom shaders, OR
  - â€¢UNIâ€¢ty particle system overlay
- Visuals adapt based on:
  - Message emotion
  - Message type (text, photo, celebration)
  - User actions (save, long-press, tap)

---

## ğŸ”ˆ 6. Optional Voice Layer

- Google Cloud TTS  
- â€¢UNIâ€¢ lines converted to audio (animated lips / sound waves optional)
- Users can toggle ON/OFF in settings

---

## ğŸ›¡ï¸ 7. Privacy & Safety

- End-to-end encrypted chat (Firebase + optional Signal Protocol)
- Memory Cards are stored privately (not public)
- No data is used to train models
- â€¢UNIâ€¢ does not store permanent chat logs beyond user-owned content

---

## ğŸ§ª Dev Approach

- MVP targets lean: ~4-week build with async loading + cloud APIs
- Heavy lifting done by cloud (DALLÂ·E, NLP, LLM)
- Frontend modular: emotion UI separated from core messaging

---

## ğŸ“ˆ Scaling Plan (Post-MVP)

- Migrate AI components to on-device models (LLM + image)
- Cache visuals for smoother UX
- Add usage analytics (privacy-safe)
- Explore local rendering for morphing effects

---

## ğŸ§  Summary

â€¢UNIâ€¢ combines AI, emotion, and generative art into a real-time commâ€¢UNIâ€¢cation engine.  
By structuring every message as an input to sentiment, scene, and character pipelines, â€¢UNIâ€¢ builds a dynamic, emotionally intelligent interface â€” the foundation of CGEI.

